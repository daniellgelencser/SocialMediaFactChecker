{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(text):\n",
    "    data_small = pd.DataFrame(np.array([text]),columns=['text'])\n",
    "\n",
    "    special_characters = '!?@#$%^&*()-+_=,<>/'\n",
    "\n",
    "    data_small['text_character_cnt'] = data_small['text'].str.len()\n",
    "    data_small['text_word_cnt'] = data_small['text'].str.split().str.len()\n",
    "\n",
    "    data_small['text_special_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if any(char in special_characters for char in x)]))\n",
    "\n",
    "    for char in special_characters:\n",
    "        data_small['text_' + char + '_per_char'] = data_small['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "        data_small['text_' + char + '_per_word'] = data_small['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "\n",
    "    data_small['text_http_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if 'http' in x]))\n",
    "    data_small['text_www_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if 'www' in x]))\n",
    "    data_small['text_number_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "    \n",
    "    return data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_html(text):\n",
    "    soup=BeautifulSoup(text,\"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]','',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    return re.sub(r'http\\S+','',text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text=[]\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop_words:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def remove_HashOrAT(text):\n",
    "    return re.sub('@|#','',text)\n",
    "\n",
    "def remove_puncuation(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "def remove_uppercase(text):\n",
    "    return text.lower()\n",
    "    \n",
    "\n",
    "def clean_text_data(text):\n",
    "    text=string_html(text)\n",
    "    text=remove_square_brackets(text)\n",
    "    text=remove_URL(text)\n",
    "    text=remove_HashOrAT(text)\n",
    "    text=remove_puncuation(text)\n",
    "    text=remove_uppercase(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1_News:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"SocialMediaFactChecker/MachineLearning/decisionTreeModel.pkl\",'rb'))\n",
    "    \n",
    "    def preditWithText(self, text):\n",
    "        return int(self.model.predict(prepare_test(text).drop(columns=['text']))[0])\n",
    "    \n",
    "    def return_str(self, text):\n",
    "        if self.preditWithText(text) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "class model1_tweets:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"SocialMediaFactChecker/MachineLearning/twitterTFModel.pkl\",'rb'))\n",
    "        self.key = realorfake = {\"True\":1,\"False\":0}\n",
    "        \n",
    "    \n",
    "    def preditWithText(self, text):\n",
    "        return self.model.predict([text])[0]\n",
    "\n",
    "    def return_str(self, text):\n",
    "        if self.preditWithText(text) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "model1 = model1_tweets()\n",
    "model2 = model1_News()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class joinmodel:\n",
    "    def __init__(self):\n",
    "        self.model1 = model1_tweets()\n",
    "        self.model2 = model1_News()\n",
    "        self.lastResult = None\n",
    "    def getTrueFalse(self, text, verbose = False):\n",
    "        result = {}\n",
    "        if type(text) != str:\n",
    "            return \"Error please feed in a string\"\n",
    "        \n",
    "        result[\"modelTweets_1\"] = self.getTweetModel_1(text)\n",
    "        result[\"modelNews_2\"] = self.getNewsModel_2(text)\n",
    "        result[\"combinedResult\"] = self.getCombinedResults(result.get(\"modelTweets_1\"), result.get(\"modelNews_2\")) \n",
    "        self.lastResult = result\n",
    "        \n",
    "        if verbose:\n",
    "            return result\n",
    "        else:\n",
    "            return result.get(\"combinedResult\")\n",
    "        \n",
    "    \n",
    "    def getTweetModel_1(self, text):\n",
    "        return self.model1.return_str(text)\n",
    "    def getNewsModel_2(self, text):\n",
    "        return self.model2.return_str(text)\n",
    "    \n",
    "    # this will be replaced with a lasso regression model trained with both models but this is a simple implemtation\n",
    "    # if both results are the same then it returns that boolean. otherwise it returns False\n",
    "    def getCombinedResults(self, model1_result, model2_result):\n",
    "        if model1_result == model2_result:\n",
    "            return model2_result\n",
    "        else: \n",
    "            return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/Uni/MS/Project/venv/lib/python3.9/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = joinmodel()\n",
    "test.getTrueFalse(\"Donald Trump is President\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/Uni/MS/Project/venv/lib/python3.9/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'modelTweets_1': False, 'modelNews_2': True, 'combinedResult': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.getTrueFalse(\"Donald Trump is President\", verbose=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "654dd77d1753ac1e3fb7ea93f4452340a94bf76edae2b51bda429fccd972a95a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

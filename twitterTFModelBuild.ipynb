{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script trains the second model on data from which can be downloaded with the following command : kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset . This Dataset is loaded into this file. These data is split into test and train datasets. These dataset are fed into a navie baysain classifer of sklearn. This model is the main model used lated in the ModelCombine File used in Django. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from keras.preprocessing import text,sequence\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Embedding\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import joblib\n",
    "import cloudpickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tristan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tristan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "datadir = 'data/twittertf'\n",
    "realorfake = {\"True\":1,\"Fake\":0}\n",
    "\n",
    "for dir in os.listdir(datadir):\n",
    "    temp_data = pd.read_csv(datadir + \"/\" +  dir)\n",
    "    temp_data = temp_data.assign(real = realorfake.get(dir.split(\".\")[0]) )\n",
    "    data = data.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19698</th>\n",
       "      <td>WOW! Governor Kasich Just Revealed How He Did ...</td>\n",
       "      <td>Ohio Governor John Kasich, who signed a pledge...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Nov 1, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18262</th>\n",
       "      <td>Critic of Rwandan president to face criminal t...</td>\n",
       "      <td>KIGALI (Reuters) - A critic of Rwandan Preside...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 5, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>Some 700 migrants rescued in Mediterranean, 23...</td>\n",
       "      <td>ROME (Reuters) - Rescuers pulled 700 boat migr...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 3, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>U.S. lawmaker: Sony breach may have inspired R...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. failure to ret...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 6, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17464</th>\n",
       "      <td>U.S.-led coalition says 100 IS fighters in Raq...</td>\n",
       "      <td>BEIRUT (Reuters) - Around 100 Islamic State fi...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 14, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "19698  WOW! Governor Kasich Just Revealed How He Did ...   \n",
       "18262  Critic of Rwandan president to face criminal t...   \n",
       "15733  Some 700 migrants rescued in Mediterranean, 23...   \n",
       "6878   U.S. lawmaker: Sony breach may have inspired R...   \n",
       "17464  U.S.-led coalition says 100 IS fighters in Raq...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "19698  Ohio Governor John Kasich, who signed a pledge...     left-news   \n",
       "18262  KIGALI (Reuters) - A critic of Rwandan Preside...     worldnews   \n",
       "15733  ROME (Reuters) - Rescuers pulled 700 boat migr...     worldnews   \n",
       "6878   WASHINGTON (Reuters) - The U.S. failure to ret...  politicsNews   \n",
       "17464  BEIRUT (Reuters) - Around 100 Islamic State fi...     worldnews   \n",
       "\n",
       "                    date  real  \n",
       "19698        Nov 1, 2016     0  \n",
       "18262   October 5, 2017      1  \n",
       "15733  November 3, 2017      1  \n",
       "6878   December 6, 2016      1  \n",
       "17464  October 14, 2017      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "punctuation=list(string.punctuation)\n",
    "stop_words.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def string_html(text):\n",
    "    soup=BeautifulSoup(text,\"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]','',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    return re.sub(r'http\\S+','',text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text=[]\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop_words:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def remove_HashOrAT(text):\n",
    "    return re.sub('@|#','',text)\n",
    "\n",
    "def remove_puncuation(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "def remove_uppercase(text):\n",
    "    return text.lower()\n",
    "    \n",
    "\n",
    "def clean_text_data(text):\n",
    "    text=string_html(text)\n",
    "    text=remove_square_brackets(text)\n",
    "    text=remove_URL(text)\n",
    "    text=remove_HashOrAT(text)\n",
    "    text=remove_puncuation(text)\n",
    "    text=remove_uppercase(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data['text']=data['text'].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.text,data.real,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline(\n",
    "    [('vec', CountVectorizer(preprocessor=clean_text_data, ngram_range=(1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=PjeOoJyPNCk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://100percentfedup.com/served-roy-moore-vietnamletter-veteran-sets-record-straight-honorable-decent-respectable-patriotic-commander-soldier/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=Ws5ojb0PCCo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?time_continue=2&v=IjWClQcKhD8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://fedup.wpengine.com/wp-content/uploads/2015/04/entitled.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=_FNt3ns_EGA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=HXJZbPAf0sk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://fedup.wpengine.com/wp-content/uploads/2015/04/hillarystreetart.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=CCr0qvehJIk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=DRLVvYzG46w\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=VkRCtn0nEvU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=wYdX071Nlow\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=P-TBfkqk7gU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=sWbYpIj7CQ8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=8Mehk5eWcZA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?time_continue=1&v=NeqMSI6OR5Q\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=IioEIUmawRo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://youtu.be/Ai5ayloRa-0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=gqxwF-TeYas\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=EOr9fwoc_mo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=hNPX8ZCIfc0&t=26s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=aHkNzBRqPCE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=IPqrimR8GWw\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://100percentfedup.com/video-hillary-asked-about-trump-i-just-want-to-eat-some-pie/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=9LNyx_DWzzA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?feature=player_embedded&v=JebHe3049aA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=-7Tn4gi_Os8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=tY0ApLE6dns\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=SH0pRtK9sAE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=31MRqr9ydUU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://youtu.be/0J4xPRYbsLU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=J4LjxrOfEF8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=8dsDdBqF828\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=cJZFepSvxzM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://youtu.be/kKFQ5i9jXmA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://twitter.com/Rosie/status/800939338615824384\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=YeDU6dCR9tA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=6VN1maBEKIk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=rUr8pYr5AXs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=zZ7GrEItGoo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=uQbAww5wajA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?time_continue=139&v=Iil1Z8-A1GA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=n9tfNMQpYWU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=1RVqTfIKGbU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=ISm-p8e-D7I\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=9LNyx_DWzzA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://youtu.be/RTuxvWjH3a4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=RRPSCqkAJgk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://twitter.com/Rosie/status/800939338615824384\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=0cVugq2GbBk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=sMHGkzrwzKg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=_FNt3ns_EGA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://youtu.be/7oOhwHG2Gb4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=IioEIUmawRo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?time_continue=139&v=Iil1Z8-A1GA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=J4LjxrOfEF8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=zZ7GrEItGoo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/home/tristan/anaconda3/envs/mir/lib/python3.8/site-packages/bs4/__init__.py:431: MarkupResemblesLocatorWarning: \"https://www.youtube.com/watch?v=uCS4RB9G13M\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9652561247216036"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Donald Trump is President of the United States\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"twitterTFModel.pkl\",'wb') as file:\n",
    "    cloudpickle.dump(text_clf, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-77c5aee844f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_text_data\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'news_2.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "pickle.dump[text_clf , 'news_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1_tweets_pk:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        self.text_clf = Pipeline(\n",
    "        [('vec', CountVectorizer(preprocessor=clean_text_data, ngram_range=(1,3))),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "        ])\n",
    "\n",
    "    def importdata(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def string_html(self, text):\n",
    "        soup=BeautifulSoup(text,\"html.parser\")\n",
    "        return soup.get_text()\n",
    "\n",
    "    def remove_square_brackets(self, text):\n",
    "        return re.sub('\\[[^]]*\\]','',text)\n",
    "\n",
    "    def remove_URL(self, text):\n",
    "        return re.sub(r'http\\S+','',text)\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        final_text=[]\n",
    "        for i in text.split():\n",
    "            if i.strip().lower() not in stop_words:\n",
    "                final_text.append(i.strip())\n",
    "        return \" \".join(final_text)\n",
    "\n",
    "    def remove_HashOrAT(self, text):\n",
    "        return re.sub('@|#','',text)\n",
    "\n",
    "    def remove_puncuation(text):\n",
    "        return text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    def remove_uppercase(self, text):\n",
    "        return text.lower()\n",
    "        \n",
    "\n",
    "    def clean_text_data(self, text):\n",
    "        text=string_html(text)\n",
    "        text=remove_square_brackets(text)\n",
    "        text=remove_URL(text)\n",
    "        text=remove_HashOrAT(text)\n",
    "        text=remove_puncuation(text)\n",
    "        text=remove_uppercase(text)\n",
    "        return text\n",
    "\n",
    "    def create_model(self):\n",
    "        self.X_train,self.X_test,self.y_train,self.y_test=train_test_split(self.data.text,self.data.real,random_state=0)\n",
    "        self.text_clf = text_clf.fit(self.X_train, self.y_train)\n",
    "    def preditWithText(self, text):\n",
    "        return self.model.predict([text])[0]\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_export = model1_tweets_pk()\n",
    "model_export.importdata(data)\n",
    "model_export.create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"twitterTFModel.pkl\",'wb') as file:\n",
    "    pickle.dump(model_export, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1_tweets:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"twitterTFModel.pkl\",'rb'))\n",
    "        self.key = realorfake = {\"True\":1,\"False\":0}\n",
    "        \n",
    "    \n",
    "    def preditWithText(self, text):\n",
    "        return self.model.predict([text])[0]\n",
    "\n",
    "    def return_str(self, text):\n",
    "        if self.preditWithText(text) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newText = model1_tweets()\n",
    "newText.preditWithText(\"Donald Trump is President\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "654dd77d1753ac1e3fb7ea93f4452340a94bf76edae2b51bda429fccd972a95a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

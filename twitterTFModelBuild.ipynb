{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from keras.preprocessing import text,sequence\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Embedding\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tristan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tristan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "datadir = '../data/twittertf'\n",
    "realorfake = {\"True\":1,\"Fake\":0}\n",
    "\n",
    "for dir in os.listdir(datadir):\n",
    "    temp_data = pd.read_csv(datadir + \"/\" +  dir)\n",
    "    temp_data = temp_data.assign(real = realorfake.get(dir.split(\".\")[0]) )\n",
    "    data = data.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Senate approves measure to kill Obama-era cont...</td>\n",
       "      <td>(Reuters) - Republicans in the U.S. Senate pas...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 6, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>Bali airport's closure due to volcano has affe...</td>\n",
       "      <td>JAKARTA (Reuters) - The closure of I Gusti Ngu...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 27, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9733</th>\n",
       "      <td>DRAMA QUEEN CHRIS MATTHEWS Claims Republican ‘...</td>\n",
       "      <td>MSNBC host Chris Matthews on Thursday accused ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Oct 7, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218</th>\n",
       "      <td>Factbox: The economy, guns top on social media...</td>\n",
       "      <td>(Reuters) - The sixth televised Republican pre...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>Trump Laughably Claims His Fake Obama Wiretap...</td>\n",
       "      <td>Remember when the world laughed at Donald Trum...</td>\n",
       "      <td>News</td>\n",
       "      <td>April 3, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "5105   Senate approves measure to kill Obama-era cont...   \n",
       "13810  Bali airport's closure due to volcano has affe...   \n",
       "9733   DRAMA QUEEN CHRIS MATTHEWS Claims Republican ‘...   \n",
       "11218  Factbox: The economy, guns top on social media...   \n",
       "1913    Trump Laughably Claims His Fake Obama Wiretap...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "5105   (Reuters) - Republicans in the U.S. Senate pas...  politicsNews   \n",
       "13810  JAKARTA (Reuters) - The closure of I Gusti Ngu...     worldnews   \n",
       "9733   MSNBC host Chris Matthews on Thursday accused ...      politics   \n",
       "11218  (Reuters) - The sixth televised Republican pre...  politicsNews   \n",
       "1913   Remember when the world laughed at Donald Trum...          News   \n",
       "\n",
       "                     date  real  \n",
       "5105       March 6, 2017      1  \n",
       "13810  November 27, 2017      1  \n",
       "9733          Oct 7, 2017     0  \n",
       "11218   January 15, 2016      1  \n",
       "1913        April 3, 2017     0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "punctuation=list(string.punctuation)\n",
    "stop_words.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_html(text):\n",
    "    soup=BeautifulSoup(text,\"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]','',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    return re.sub(r'http\\S+','',text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text=[]\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop_words:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def remove_HashOrAT(text):\n",
    "    return re.sub('@|#','',text)\n",
    "\n",
    "def remove_puncuation(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "def remove_uppercase(text):\n",
    "    return text.lower()\n",
    "    \n",
    "\n",
    "def clean_text_data(text):\n",
    "    text=string_html(text)\n",
    "    text=remove_square_brackets(text)\n",
    "    text=remove_URL(text)\n",
    "    text=remove_HashOrAT(text)\n",
    "    text=remove_puncuation(text)\n",
    "    text=remove_uppercase(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data['text']=data['text'].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.text,data.real,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline(\n",
    "    [('vec', CountVectorizer(preprocessor=clean_text_data, ngram_range=(1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694432071269488"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Donald Trump is President of the United States\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"twitterTFModel.pkl\",'wb') as file:\n",
    "    pickle.dump(text_clf, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1_tweets:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"twitterTFModel.pkl\",'rb'))\n",
    "        self.key = realorfake = {\"True\":1,\"False\":0}\n",
    "        \n",
    "    \n",
    "    def preditWithText(self, text):\n",
    "        return self.model.predict([text])[0]\n",
    "\n",
    "    def return_str(self, text):\n",
    "        if self.preditWithText(text) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newText = model1_tweets()\n",
    "newText.preditWithText(\"Donald Trump is President\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "654dd77d1753ac1e3fb7ea93f4452340a94bf76edae2b51bda429fccd972a95a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

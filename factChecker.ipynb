{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.1 MB 3.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/tristan/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/tristan/anaconda3/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as pyplot\n",
    "import seaborn\n",
    "import nltk\n",
    "import gensim\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tristan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tristan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['authors', 'canonical_link', 'images', 'keywords', 'meta_data',\n",
       "       'movies', 'publish_date', 'real', 'source', 'summary', 'text', 'title',\n",
       "       'top_img', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.DataFrame()\n",
    "realorfake = {\"real\":1,\"fake\":0}\n",
    "\n",
    "for dir in os.listdir('../data/politifact'):\n",
    "    for datadir in os.listdir('../data/politifact/' + dir):\n",
    "        try:\n",
    "            with open('../data/politifact/' + dir + '/' + datadir + '/news content.json') as json_file:\n",
    "                json_obj = json.load(json_file)\n",
    "                json_obj['real'] = realorfake.get(dir)\n",
    "                data = data.append(json_obj, ignore_index=True)\n",
    "        except Exception:\n",
    "            None\n",
    "        finally:\n",
    "            None\n",
    "\n",
    "\n",
    "\n",
    "data.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>canonical_link</th>\n",
       "      <th>images</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_data</th>\n",
       "      <th>movies</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>real</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>top_img</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[February]</td>\n",
       "      <td>https://www.politifact.com/factchecks/2010/feb...</td>\n",
       "      <td>[https://static.politifact.com/CACHE/images/po...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'viewport': 'width=device-width, initial-scal...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1265238000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://politifact.com</td>\n",
       "      <td></td>\n",
       "      <td>The recent Massachusetts Senate election capti...</td>\n",
       "      <td>Krugman calls Senate health care bill similar ...</td>\n",
       "      <td>https://static.politifact.com/politifact/rulin...</td>\n",
       "      <td>http://politifact.com/truth-o-meter/statements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.guttmacher.org/laws-affecting-repr...</td>\n",
       "      <td>[https://www.guttmacher.org/sites/default/file...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'MobileOptimized': 'width', 'HandheldFriendly...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1388513502.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.guttmacher.org</td>\n",
       "      <td></td>\n",
       "      <td>by Elizabeth Nash, Rachel Benson Gold, Andrea ...</td>\n",
       "      <td>Laws Affecting Reproductive Health and Rights:...</td>\n",
       "      <td>https://www.guttmacher.org/sites/default/files...</td>\n",
       "      <td>http://www.guttmacher.org/statecenter/updates/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Abc News, January]</td>\n",
       "      <td>https://abcnews.go.com/ThisWeek/week-transcrip...</td>\n",
       "      <td>[data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'description': 'Transcript of 'This Week' int...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://abcnews.go.com</td>\n",
       "      <td></td>\n",
       "      <td>August 8, 2010  -- AMANPOUR: Good morning. I'...</td>\n",
       "      <td>'This Week' Transcript: Odierno and Chiarelli</td>\n",
       "      <td>http://abcnews.go.com/ThisWeek/week-transcript...</td>\n",
       "      <td>http://abcnews.go.com/ThisWeek/week-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>https://ohioart.com/etch-a-sketch-sold-to-spin...</td>\n",
       "      <td>[https://ohioart.com/wp-content/uploads/2016/0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'viewport': 'width=device-width, initial-scal...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.ohioart.com</td>\n",
       "      <td></td>\n",
       "      <td>In February of 2016, we announced the sale of ...</td>\n",
       "      <td>Sale of the Etch A Sketch Brand</td>\n",
       "      <td>https://ohioart.com/wp-content/uploads/2016/03...</td>\n",
       "      <td>http://www.ohioart.com/etch/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Gardiner Harris]</td>\n",
       "      <td>https://www.nytimes.com/2009/02/03/health/poli...</td>\n",
       "      <td>[https://static01.nyt.com/newsgraphics/images/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'robots': 'noarchive', 'description': 'Federa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1233615600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.nytimes.com</td>\n",
       "      <td></td>\n",
       "      <td>WASHINGTON  Even though federal health offici...</td>\n",
       "      <td>Peanut Product Recall Took Company Approval</td>\n",
       "      <td>https://static01.nyt.com/newsgraphics/images/i...</td>\n",
       "      <td>http://www.nytimes.com/2009/02/03/health/polic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors                                     canonical_link  \\\n",
       "0           [February]  https://www.politifact.com/factchecks/2010/feb...   \n",
       "1                   []  https://www.guttmacher.org/laws-affecting-repr...   \n",
       "2  [Abc News, January]  https://abcnews.go.com/ThisWeek/week-transcrip...   \n",
       "3                   []  https://ohioart.com/etch-a-sketch-sold-to-spin...   \n",
       "4    [Gardiner Harris]  https://www.nytimes.com/2009/02/03/health/poli...   \n",
       "\n",
       "                                              images keywords  \\\n",
       "0  [https://static.politifact.com/CACHE/images/po...       []   \n",
       "1  [https://www.guttmacher.org/sites/default/file...       []   \n",
       "2  [data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/...       []   \n",
       "3  [https://ohioart.com/wp-content/uploads/2016/0...       []   \n",
       "4  [https://static01.nyt.com/newsgraphics/images/...       []   \n",
       "\n",
       "                                           meta_data movies  publish_date  \\\n",
       "0  {'viewport': 'width=device-width, initial-scal...     []  1265238000.0   \n",
       "1  {'MobileOptimized': 'width', 'HandheldFriendly...     []  1388513502.0   \n",
       "2  {'description': 'Transcript of 'This Week' int...     []          None   \n",
       "3  {'viewport': 'width=device-width, initial-scal...     []          None   \n",
       "4  {'robots': 'noarchive', 'description': 'Federa...     []  1233615600.0   \n",
       "\n",
       "   real                     source summary  \\\n",
       "0   1.0      http://politifact.com           \n",
       "1   1.0  http://www.guttmacher.org           \n",
       "2   1.0      http://abcnews.go.com           \n",
       "3   1.0     http://www.ohioart.com           \n",
       "4   1.0     http://www.nytimes.com           \n",
       "\n",
       "                                                text  \\\n",
       "0  The recent Massachusetts Senate election capti...   \n",
       "1  by Elizabeth Nash, Rachel Benson Gold, Andrea ...   \n",
       "2  August 8, 2010  -- AMANPOUR: Good morning. I'...   \n",
       "3  In February of 2016, we announced the sale of ...   \n",
       "4  WASHINGTON  Even though federal health offici...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Krugman calls Senate health care bill similar ...   \n",
       "1  Laws Affecting Reproductive Health and Rights:...   \n",
       "2      'This Week' Transcript: Odierno and Chiarelli   \n",
       "3                    Sale of the Etch A Sketch Brand   \n",
       "4        Peanut Product Recall Took Company Approval   \n",
       "\n",
       "                                             top_img  \\\n",
       "0  https://static.politifact.com/politifact/rulin...   \n",
       "1  https://www.guttmacher.org/sites/default/files...   \n",
       "2  http://abcnews.go.com/ThisWeek/week-transcript...   \n",
       "3  https://ohioart.com/wp-content/uploads/2016/03...   \n",
       "4  https://static01.nyt.com/newsgraphics/images/i...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://politifact.com/truth-o-meter/statements...  \n",
       "1  http://www.guttmacher.org/statecenter/updates/...  \n",
       "2  http://abcnews.go.com/ThisWeek/week-transcript...  \n",
       "3                       http://www.ohioart.com/etch/  \n",
       "4  http://www.nytimes.com/2009/02/03/health/polic...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = '!?@#$%^&*()-+_=,<>/'\n",
    "\n",
    "data['text_character_cnt'] = data['text'].str.len()\n",
    "# if(data['text_character_cnt'] > 0):\n",
    "data['text_word_cnt'] = data['text'].str.split().str.len()\n",
    "# data['text_character_per_word'] = data['text_character_cnt'] / data['text_word_cnt']\n",
    "\n",
    "data['text_special_cnt'] = data['text'].apply(lambda x: len([x for x in x.split() if any(char in special_characters for char in x)]))\n",
    "\n",
    "for char in special_characters:\n",
    "    data['text_' + char + '_per_char'] = data['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "    data['text_' + char + '_per_word'] = data['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "\n",
    "data['text_http_cnt'] = data['text'].apply(lambda x: len([x for x in x.split() if 'http' in x]))\n",
    "data['text_www_cnt'] = data['text'].apply(lambda x: len([x for x in x.split() if 'www' in x]))\n",
    "data['text_number_cnt'] = data['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "\n",
    "#data['title_character_cnt'] = data['title'].str.len()\n",
    "# if(data['title_character_cnt'] > 0):\n",
    "#data['title_word_cnt'] = data['title'].str.split().str.len()\n",
    "# data['title_character_per_word'] = data['title_character_cnt'] / data['title_word_cnt']\n",
    "\n",
    "#data['special_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if any(char in special_characters for char in x)]))\n",
    "\n",
    "#for char in special_characters:\n",
    "#    data['title_' + char + '_per_char'] = data['title'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "#    data['title_' + char + '_per_word'] = data['title'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "\n",
    "#data['title_http_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if 'http' in x]))\n",
    "#data['title_www_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if 'www' in x]))\n",
    "#data['title_number_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(text):\n",
    "    data_small = pandas.DataFrame(numpy.array([text]),columns=['text'])\n",
    "\n",
    "\n",
    "\n",
    "    special_characters = '!?@#$%^&*()-+_=,<>/'\n",
    "\n",
    "    data_small['text_character_cnt'] = data_small['text'].str.len()\n",
    "    # if(data['text_character_cnt'] > 0):\n",
    "    data_small['text_word_cnt'] = data_small['text'].str.split().str.len()\n",
    "    # data['text_character_per_word'] = data['text_character_cnt'] / data['text_word_cnt']\n",
    "\n",
    "    data_small['text_special_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if any(char in special_characters for char in x)]))\n",
    "\n",
    "    for char in special_characters:\n",
    "        data_small['text_' + char + '_per_char'] = data_small['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "        data_small['text_' + char + '_per_word'] = data_small['text'].apply(lambda x: len([x for x in x.split() if char in x]))\n",
    "\n",
    "    data_small['text_http_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if 'http' in x]))\n",
    "    data_small['text_www_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if 'www' in x]))\n",
    "    data_small['text_number_cnt'] = data_small['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "    \n",
    "    return data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_character_cnt</th>\n",
       "      <th>text_word_cnt</th>\n",
       "      <th>text_special_cnt</th>\n",
       "      <th>text_!_per_char</th>\n",
       "      <th>text_!_per_word</th>\n",
       "      <th>text_?_per_char</th>\n",
       "      <th>text_?_per_word</th>\n",
       "      <th>text_@_per_char</th>\n",
       "      <th>text_@_per_word</th>\n",
       "      <th>text_#_per_char</th>\n",
       "      <th>...</th>\n",
       "      <th>text_,_per_word</th>\n",
       "      <th>text_&lt;_per_char</th>\n",
       "      <th>text_&lt;_per_word</th>\n",
       "      <th>text_&gt;_per_char</th>\n",
       "      <th>text_&gt;_per_word</th>\n",
       "      <th>text_/_per_char</th>\n",
       "      <th>text_/_per_word</th>\n",
       "      <th>text_http_cnt</th>\n",
       "      <th>text_www_cnt</th>\n",
       "      <th>text_number_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>1299</td>\n",
       "      <td>238</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5451</td>\n",
       "      <td>902</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2197</td>\n",
       "      <td>371</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>3316</td>\n",
       "      <td>559</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>17517</td>\n",
       "      <td>2808</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2065</td>\n",
       "      <td>348</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>11053</td>\n",
       "      <td>1652</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_character_cnt  text_word_cnt  text_special_cnt  text_!_per_char  \\\n",
       "675                1299            238                11                0   \n",
       "610                5451            902                51                0   \n",
       "766                2197            371                22                0   \n",
       "651                  37              8                 0                0   \n",
       "883                3316            559                40                0   \n",
       "..                  ...            ...               ...              ...   \n",
       "269               17517           2808               244                0   \n",
       "768                2065            348                22                0   \n",
       "418               11053           1652                94                0   \n",
       "474                   0              0                 0                0   \n",
       "244                   0              0                 0                0   \n",
       "\n",
       "     text_!_per_word  text_?_per_char  text_?_per_word  text_@_per_char  \\\n",
       "675                0                2                2                0   \n",
       "610                0                0                0                0   \n",
       "766                0                0                0                0   \n",
       "651                0                0                0                0   \n",
       "883                0                1                1                0   \n",
       "..               ...              ...              ...              ...   \n",
       "269                0                2                2                0   \n",
       "768                0                1                1                0   \n",
       "418                0                6                6                0   \n",
       "474                0                0                0                0   \n",
       "244                0                0                0                0   \n",
       "\n",
       "     text_@_per_word  text_#_per_char  ...  text_,_per_word  text_<_per_char  \\\n",
       "675                0                0  ...                8                0   \n",
       "610                0                0  ...               44                0   \n",
       "766                0                0  ...               20                0   \n",
       "651                0                0  ...                0                0   \n",
       "883                0                0  ...               22                0   \n",
       "..               ...              ...  ...              ...              ...   \n",
       "269                0                0  ...              166                0   \n",
       "768                0                0  ...               18                0   \n",
       "418                0                0  ...               68                0   \n",
       "474                0                0  ...                0                0   \n",
       "244                0                0  ...                0                0   \n",
       "\n",
       "     text_<_per_word  text_>_per_char  text_>_per_word  text_/_per_char  \\\n",
       "675                0                0                0                0   \n",
       "610                0                0                0                1   \n",
       "766                0                0                0                0   \n",
       "651                0                0                0                0   \n",
       "883                0                0                0                1   \n",
       "..               ...              ...              ...              ...   \n",
       "269                0                0                0                1   \n",
       "768                0                0                0                0   \n",
       "418                0                0                0                0   \n",
       "474                0                0                0                0   \n",
       "244                0                0                0                0   \n",
       "\n",
       "     text_/_per_word  text_http_cnt  text_www_cnt  text_number_cnt  \n",
       "675                0              0             0                0  \n",
       "610                1              0             0                4  \n",
       "766                0              0             0                2  \n",
       "651                0              0             0                0  \n",
       "883                1              0             0                4  \n",
       "..               ...            ...           ...              ...  \n",
       "269                1              0             0               26  \n",
       "768                0              0             0                1  \n",
       "418                0              0             0               18  \n",
       "474                0              0             0                0  \n",
       "244                0              0             0                0  \n",
       "\n",
       "[767 rows x 44 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['url', 'text', 'images', 'top_img', 'keywords', 'authors',\n",
    "       'canonical_link', 'title', 'meta_data', 'movies', 'publish_date',\n",
    "       'source', 'summary', 'real'])\n",
    "Y = data['real']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "score = accuracy_score(Y_test, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"decisionTreeModel.pkl\", 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prepare_test(\"Donald Trump is President\").drop(columns=['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_character_cnt</th>\n",
       "      <th>text_word_cnt</th>\n",
       "      <th>text_special_cnt</th>\n",
       "      <th>text_!_per_char</th>\n",
       "      <th>text_!_per_word</th>\n",
       "      <th>text_?_per_char</th>\n",
       "      <th>text_?_per_word</th>\n",
       "      <th>text_@_per_char</th>\n",
       "      <th>text_@_per_word</th>\n",
       "      <th>...</th>\n",
       "      <th>text_,_per_word</th>\n",
       "      <th>text_&lt;_per_char</th>\n",
       "      <th>text_&lt;_per_word</th>\n",
       "      <th>text_&gt;_per_char</th>\n",
       "      <th>text_&gt;_per_word</th>\n",
       "      <th>text_/_per_char</th>\n",
       "      <th>text_/_per_word</th>\n",
       "      <th>text_http_cnt</th>\n",
       "      <th>text_www_cnt</th>\n",
       "      <th>text_number_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump is President</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  text_character_cnt  text_word_cnt  \\\n",
       "0  Donald Trump is President                  25              4   \n",
       "\n",
       "   text_special_cnt  text_!_per_char  text_!_per_word  text_?_per_char  \\\n",
       "0                 0                0                0                0   \n",
       "\n",
       "   text_?_per_word  text_@_per_char  text_@_per_word  ...  text_,_per_word  \\\n",
       "0                0                0                0  ...                0   \n",
       "\n",
       "   text_<_per_char  text_<_per_word  text_>_per_char  text_>_per_word  \\\n",
       "0                0                0                0                0   \n",
       "\n",
       "   text_/_per_char  text_/_per_word  text_http_cnt  text_www_cnt  \\\n",
       "0                0                0              0             0   \n",
       "\n",
       "   text_number_cnt  \n",
       "0                0  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class model1_News:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"decisionTreeModel.pkl\",'rb'))\n",
    "    \n",
    "    def preditWithText(self, text):\n",
    "        self.model.predit(prepare_test(text).drop(columns=['text']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['url', 'text', 'images', 'top_img', 'keywords', 'authors',\n",
    "       'canonical_link', 'title', 'meta_data', 'movies', 'publish_date',\n",
    "       'source', 'summary', 'real', \"title_character_cnt\",  \"title_word_cnt\",       \"special_cnt\",          \"title_!_per_char\",    \n",
    "\"title_!_per_word\",    \"title_?_per_char\",    \"title_?_per_word\",    \"title_@_per_char\",    \n",
    "\"title_@_per_word\",    \"title_#_per_char\",    \"title_#_per_word\",    \"title_$_per_char\",    \n",
    "\"title_$_per_word\",    \"title_%_per_char\",    \"title_%_per_word\",    \"title_^_per_char\",    \n",
    "\"title_^_per_word\",    \"title_&_per_char\",    \"title_&_per_word\",    \"title_*_per_char\",    \n",
    "\"title_*_per_word\",    \"title_(_per_char\",    \"title_(_per_word\",    \"title_)_per_char\",    \n",
    "\"title_)_per_word\",    \"title_-_per_char\",    \"title_-_per_word\",    \"title_+_per_char\",    \n",
    "\"title_+_per_word\",    \"title___per_char\",    \"title___per_word\",    \"title_=_per_char\",    \n",
    "\"title_=_per_word\",    \"title_,_per_char\",    \"title_,_per_word\",    \"title_<_per_char\",    \n",
    "\"title_<_per_word\",    \"title_>_per_char\",    \"title_>_per_word\",    \"title_/_per_char\",    \n",
    "\"title_/_per_word\",    \"title_http_cnt\",    \"title_www_cnt\",    \"title_number_cnt\"    ])\n",
    "\n",
    "Y = data['real']\n",
    "\n",
    "X_train_limited, X_test_limited, Y_train_limited, Y_test_limited = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_character_cnt</th>\n",
       "      <th>text_word_cnt</th>\n",
       "      <th>text_special_cnt</th>\n",
       "      <th>text_!_per_char</th>\n",
       "      <th>text_!_per_word</th>\n",
       "      <th>text_?_per_char</th>\n",
       "      <th>text_?_per_word</th>\n",
       "      <th>text_@_per_char</th>\n",
       "      <th>text_@_per_word</th>\n",
       "      <th>text_#_per_char</th>\n",
       "      <th>...</th>\n",
       "      <th>text_,_per_word</th>\n",
       "      <th>text_&lt;_per_char</th>\n",
       "      <th>text_&lt;_per_word</th>\n",
       "      <th>text_&gt;_per_char</th>\n",
       "      <th>text_&gt;_per_word</th>\n",
       "      <th>text_/_per_char</th>\n",
       "      <th>text_/_per_word</th>\n",
       "      <th>text_http_cnt</th>\n",
       "      <th>text_www_cnt</th>\n",
       "      <th>text_number_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7892</td>\n",
       "      <td>1258</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23903</td>\n",
       "      <td>3627</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44882</td>\n",
       "      <td>7805</td>\n",
       "      <td>666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2437</td>\n",
       "      <td>395</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975</td>\n",
       "      <td>162</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_character_cnt  text_word_cnt  text_special_cnt  text_!_per_char  \\\n",
       "0                7892           1258               102                0   \n",
       "1               23903           3627               241                0   \n",
       "2               44882           7805               666                0   \n",
       "3                2437            395                19                0   \n",
       "4                 975            162                 4                0   \n",
       "\n",
       "   text_!_per_word  text_?_per_char  text_?_per_word  text_@_per_char  \\\n",
       "0                0                3                3                0   \n",
       "1                0                0                0                0   \n",
       "2                0               59               59                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   text_@_per_word  text_#_per_char  ...  text_,_per_word  text_<_per_char  \\\n",
       "0                0                0  ...               71                0   \n",
       "1                0                0  ...              141                0   \n",
       "2                0                0  ...              474                0   \n",
       "3                0                0  ...               18                0   \n",
       "4                0                0  ...                4                0   \n",
       "\n",
       "   text_<_per_word  text_>_per_char  text_>_per_word  text_/_per_char  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                1   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   text_/_per_word  text_http_cnt  text_www_cnt  text_number_cnt  \n",
       "0                0              0             0               10  \n",
       "1                0              0             0               50  \n",
       "2                1              0             0               23  \n",
       "3                0              0             0                3  \n",
       "4                0              0             0                0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734375"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_limited, Y_train_limited)\n",
    "\n",
    "prediction = model.predict(X_test_limited)\n",
    "score = accuracy_score(Y_test_limited, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"decisionTreeModel_noTitle.pkl\", 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_data = pandas.concat([\n",
    "#     pandas.read_csv('dataset/gossipcop_real.csv'),\n",
    "#     pandas.read_csv('dataset/politifact_fake.csv')\n",
    "# ], ignore_index=True)\n",
    "# real_data['real'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pandas.concat([fake_data, real_data], ignore_index=True)\n",
    "# data = data.sample(frac=1)\n",
    "# data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['character_cnt'] = data['title'].str.len()\n",
    "data['word_cnt'] = data['title'].str.split().str.len()\n",
    "data['character_per_word'] = data['character_cnt'] / data['word_cnt']\n",
    "\n",
    "special_characters = '!?@#$%^&*()-+_=,<>/'\n",
    "data['special_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if any(char in special_characters for char in x)]))\n",
    "\n",
    "data['hashtag_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if '#' in x]))\n",
    "data['at_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if '@' in x]))\n",
    "data['explanation_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if '!' in x]))\n",
    "data['question_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if '?' in x]))\n",
    "data['interrobang_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if '?!' in x]))\n",
    "data['ellipsis_cnt'] = data['title'].apply(lambda x: len([x for datax in x.split() if '...' in x]))\n",
    "data['semicolon_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if ';' in x]))\n",
    "\n",
    "data['http_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if 'http' in x]))\n",
    "data['www_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if 'www' in x]))\n",
    "\n",
    "data['number_cnt'] = data['title'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...\n",
       "1      [[(11, 1), (12, 1), (13, 1), (14, 1), (15, 1),...\n",
       "2      [[(12, 1), (21, 1), (22, 1), (23, 1), (24, 1),...\n",
       "3      [[(28, 1), (29, 1), (30, 1), (31, 1), (32, 1),...\n",
       "4      [[(35, 1), (36, 1), (37, 1), (38, 1), (39, 1),...\n",
       "                             ...                        \n",
       "954    [[(21, 1), (33, 1), (3184, 1), (3469, 1), (347...\n",
       "955    [[(135, 1), (140, 1), (339, 1), (500, 1), (540...\n",
       "956    [[(10, 1), (33, 1), (47, 1), (117, 1), (217, 1...\n",
       "957    [[(160, 1), (433, 1), (485, 1), (528, 1), (802...\n",
       "958    [[(33, 1), (34, 1), (97, 1), (135, 1), (140, 1...\n",
       "Name: title_words, Length: 959, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data['title_words'] = data['title'].apply(lambda x: word_tokenize(x))\n",
    "data['title_sentences'] = data['title'].apply(lambda x: sent_tokenize(x))\n",
    "title_word_dict = gensim.corpora.Dictionary(data['title_words'])\n",
    "title_sentence_dict = gensim.corpora.Dictionary(data['title_sentences'])\n",
    "# title_word_dict = data['title_words'].apply(lambda x: gensim.corpora.Dictionary(x))\n",
    "data['title_words'] = data['title_words'].apply(lambda x: [title_word_dict.doc2bow(x) for word in x])\n",
    "data['title_sentences'] = data['title_sentences'].apply(lambda x: [title_sentence_dict.doc2bow(x) for word in x])\n",
    "\n",
    "data['title_words']\n",
    "\n",
    "# data['title_corpus']\n",
    "\n",
    "# corpus = [title_word_dict.doc2bow(data['title_words']) for word in data['title_words']]\n",
    "\n",
    "\n",
    "# data['processed_title'] = data['title'].str.replace('[^\\w\\s]', '')\n",
    "# data['processed_title'] = data['processed_title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# data['processed_title'] = data['processed_title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# stemmer = PorterStemmer()\n",
    "# data['processed_title'] = data['processed_title'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidvector = TfidfVectorizer(max_features=500, lowercase=True, analyzer='word', stop_words='english', ngram_range=(1, 1))\n",
    "\n",
    "# data_vector = tfidvector.fit_transform(data['processed_title'])\n",
    "\n",
    "# for name, value in zip(tfidvector.get_feature_names_out(), tfidvector.idf_):\n",
    "#     print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index' 'id' 'news_url' 'tweet_ids'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2837/2540492623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news_url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tweet_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/MMS/Project/SocialMediaFactChecker/venv/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/MMS/Project/SocialMediaFactChecker/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/MMS/Project/SocialMediaFactChecker/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/MMS/Project/SocialMediaFactChecker/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/MMS/Project/SocialMediaFactChecker/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index' 'id' 'news_url' 'tweet_ids'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['title', 'index', 'id', 'news_url', 'tweet_ids'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-2bae4072042f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    158\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['real'])\n",
    "Y = data['real']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "score = accuracy_score(Y_test, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1375c670ee5f5aa255916eacc89fe4f0e38c25cf8703a8220a4512e9d04ef996"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
